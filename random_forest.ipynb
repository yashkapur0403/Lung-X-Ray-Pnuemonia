{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashkapur0403/Neural-Networks-Practise/blob/main/random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "zN4O2KSA9Twi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a734db13-f80c-4b8a-e8cd-afef21c45092"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import zipfile, os, cv2\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')  # allow permission\n",
        "zip_path = \"/content/drive/My Drive/Colab Notebooks/chest_xray.zip\"\n",
        "extract_path = \"/content/chest_xray\"\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# STEP 2: Load images and prepare data\n",
        "def load_images_from_folder(folder_path, label):\n",
        "    data = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, (64, 64))\n",
        "            img_flat = img.flatten() / 255.0\n",
        "            data.append((img_flat, label))\n",
        "    return data\n",
        "\n",
        "normal_data = load_images_from_folder(\"/content/chest_xray/chest_xray/train/NORMAL\", 0)\n",
        "pneumonia_data = load_images_from_folder(\"/content/chest_xray/chest_xray/train/PNEUMONIA\", 1)\n",
        "all_data = normal_data + pneumonia_data\n",
        "\n",
        "X_train = np.array([x for x, _ in all_data])\n",
        "y_train = np.array([y for _, y in all_data])\n",
        "\n",
        "normal_test = load_images_from_folder(\"/content/chest_xray/chest_xray/test/NORMAL\", 0)\n",
        "pneumonia_test = load_images_from_folder(\"/content/chest_xray/chest_xray/test/PNEUMONIA\", 1)\n",
        "all_test = normal_test + pneumonia_test\n",
        "\n",
        "X_test = np.array([x for x, _ in all_test])\n",
        "y_test = np.array([y for _, y in all_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "gJBrhvsi9faF"
      },
      "outputs": [],
      "source": [
        "# Gini Impurity\n",
        "def gini(y):\n",
        "    classes, counts = np.unique(y, return_counts=True)\n",
        "    probs = counts / counts.sum()\n",
        "    return 1 - np.sum(probs ** 2)\n",
        "\n",
        "# Splitting the dataset\n",
        "def split(X, y, feature_index, threshold):\n",
        "    left_mask = X[:, feature_index] <= threshold\n",
        "    right_mask = ~left_mask\n",
        "    return X[left_mask], y[left_mask], X[right_mask], y[right_mask]\n",
        "\n",
        "# Best split - EFFICIENT VERSION\n",
        "def best_split(X, y):\n",
        "    m, n = X.shape\n",
        "    best_gini = 1\n",
        "    best_idx, best_thresh = None, None\n",
        "\n",
        "    for feature_index in range(n):\n",
        "        feature_values = X[:, feature_index]\n",
        "        min_val, max_val = feature_values.min(), feature_values.max()\n",
        "\n",
        "        # Use fewer thresholds but better distributed\n",
        "        if min_val == max_val:\n",
        "            continue\n",
        "\n",
        "        # Sample 15 thresholds between min and max\n",
        "        thresholds = np.linspace(min_val, max_val, 15)[1:-1]\n",
        "\n",
        "        for t in thresholds:\n",
        "            _, y_left, _, y_right = split(X, y, feature_index, t)\n",
        "            if len(y_left) == 0 or len(y_right) == 0:\n",
        "                continue\n",
        "\n",
        "            # Add minimum samples requirement to prevent overfitting\n",
        "            if len(y_left) < 5 or len(y_right) < 5:\n",
        "                continue\n",
        "\n",
        "            g = (len(y_left) * gini(y_left) + len(y_right) * gini(y_right)) / m\n",
        "            if g < best_gini:\n",
        "                best_gini = g\n",
        "                best_idx = feature_index\n",
        "                best_thresh = t\n",
        "    return best_idx, best_thresh\n",
        "\n",
        "# Build the tree\n",
        "class Node:\n",
        "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
        "        self.feature_index = feature_index\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value\n",
        "\n",
        "def build_tree(X, y, depth=0, max_depth=8, min_samples_split=10):\n",
        "    # Add more stopping conditions to prevent overfitting\n",
        "    print(f\"Tree depth: {depth}, Samples: {len(y)}\")\n",
        "    if (len(set(y)) == 1 or\n",
        "        depth == max_depth or\n",
        "        len(y) < min_samples_split):\n",
        "        # Leaf node\n",
        "        values, counts = np.unique(y, return_counts=True)\n",
        "        return Node(value=values[np.argmax(counts)])\n",
        "\n",
        "    feat_idx, thresh = best_split(X, y)\n",
        "    if feat_idx is None:\n",
        "        values, counts = np.unique(y, return_counts=True)\n",
        "        return Node(value=values[np.argmax(counts)])\n",
        "\n",
        "    X_left, y_left, X_right, y_right = split(X, y, feat_idx, thresh)\n",
        "\n",
        "    # Ensure minimum samples in each split\n",
        "    if len(y_left) < 5 or len(y_right) < 5:\n",
        "        values, counts = np.unique(y, return_counts=True)\n",
        "        return Node(value=values[np.argmax(counts)])\n",
        "\n",
        "    left_child = build_tree(X_left, y_left, depth + 1, max_depth, min_samples_split)\n",
        "    right_child = build_tree(X_right, y_right, depth + 1, max_depth, min_samples_split)\n",
        "    return Node(feature_index=feat_idx, threshold=thresh, left=left_child, right=right_child)\n",
        "\n",
        "# Predict\n",
        "def predict_one(x, node):\n",
        "    if node.value is not None:\n",
        "        return node.value\n",
        "    if x[node.feature_index] <= node.threshold:\n",
        "        return predict_one(x, node.left)\n",
        "    else:\n",
        "        return predict_one(x, node.right)\n",
        "\n",
        "def predict(X, tree):\n",
        "    return np.array([predict_one(row, tree) for row in X])\n",
        "\n",
        "# Shuffle data manually without sklearn\n",
        "def manual_shuffle(X, y, random_state=42):\n",
        "    np.random.seed(random_state)\n",
        "    indices = np.random.permutation(len(X))\n",
        "    return X[indices], y[indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4TPhDhgC9iW8"
      },
      "outputs": [],
      "source": [
        "class RandomForest:\n",
        "    def __init__(self, n_trees=5, max_depth=5, min_samples_split=30):   # <- FIXED HERE\n",
        "        self.n_trees = n_trees\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.trees = []\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.trees = []\n",
        "        for i in range(self.n_trees):\n",
        "            print(f\"Training tree {i+1}/{self.n_trees}\")  # ðŸ§  Add this line\n",
        "\n",
        "            idxs = np.random.choice(len(X_train), len(X_train), replace=True)\n",
        "            X_sample, y_sample = X_train[idxs], y_train[idxs]\n",
        "            tree = build_tree(X_sample, y_sample,\n",
        "                              max_depth=self.max_depth,\n",
        "                              min_samples_split=self.min_samples_split)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, X):\n",
        "        tree_preds = np.array([predict(X, tree) for tree in self.trees])\n",
        "        return np.array([\n",
        "            np.bincount(tree_preds[:, i]).argmax()\n",
        "            for i in range(len(X))\n",
        "        ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2voJLY7-yw1",
        "outputId": "a7565993-82e5-4a11-ea0a-6bef27fd2246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training tree 1/10\n",
            "Tree depth: 0, Samples: 200\n",
            "Tree depth: 1, Samples: 56\n",
            "Tree depth: 2, Samples: 11\n",
            "Tree depth: 2, Samples: 45\n",
            "Tree depth: 3, Samples: 35\n",
            "Tree depth: 3, Samples: 10\n",
            "Tree depth: 1, Samples: 144\n",
            "Tree depth: 2, Samples: 7\n",
            "Tree depth: 2, Samples: 137\n",
            "Tree depth: 3, Samples: 131\n",
            "Tree depth: 3, Samples: 6\n",
            "Training tree 2/10\n",
            "Tree depth: 0, Samples: 200\n",
            "Tree depth: 1, Samples: 124\n",
            "Tree depth: 2, Samples: 106\n",
            "Tree depth: 3, Samples: 100\n",
            "Tree depth: 3, Samples: 6\n",
            "Tree depth: 2, Samples: 18\n",
            "Tree depth: 1, Samples: 76\n",
            "Tree depth: 2, Samples: 60\n",
            "Tree depth: 3, Samples: 50\n",
            "Tree depth: 3, Samples: 10\n",
            "Tree depth: 2, Samples: 16\n",
            "Training tree 3/10\n",
            "Tree depth: 0, Samples: 200\n",
            "Tree depth: 1, Samples: 148\n",
            "Tree depth: 2, Samples: 136\n",
            "Tree depth: 3, Samples: 8\n",
            "Tree depth: 3, Samples: 128\n",
            "Tree depth: 2, Samples: 12\n",
            "Tree depth: 1, Samples: 52\n",
            "Tree depth: 2, Samples: 38\n",
            "Tree depth: 3, Samples: 5\n",
            "Tree depth: 3, Samples: 33\n",
            "Tree depth: 2, Samples: 14\n",
            "Training tree 4/10\n",
            "Tree depth: 0, Samples: 200\n",
            "Tree depth: 1, Samples: 136\n",
            "Tree depth: 2, Samples: 129\n",
            "Tree depth: 3, Samples: 5\n",
            "Tree depth: 3, Samples: 124\n",
            "Tree depth: 2, Samples: 7\n",
            "Tree depth: 1, Samples: 64\n",
            "Tree depth: 2, Samples: 51\n",
            "Tree depth: 3, Samples: 5\n",
            "Tree depth: 3, Samples: 46\n",
            "Tree depth: 2, Samples: 13\n",
            "Training tree 5/10\n",
            "Tree depth: 0, Samples: 200\n",
            "Tree depth: 1, Samples: 77\n",
            "Tree depth: 2, Samples: 14\n",
            "Tree depth: 2, Samples: 63\n",
            "Tree depth: 3, Samples: 56\n",
            "Tree depth: 3, Samples: 7\n",
            "Tree depth: 1, Samples: 123\n",
            "Tree depth: 2, Samples: 113\n",
            "Tree depth: 3, Samples: 104\n",
            "Tree depth: 3, Samples: 9\n",
            "Tree depth: 2, Samples: 10\n",
            "Training tree 6/10\n",
            "Tree depth: 0, Samples: 200\n",
            "Tree depth: 1, Samples: 140\n",
            "Tree depth: 2, Samples: 130\n",
            "Tree depth: 3, Samples: 6\n",
            "Tree depth: 3, Samples: 124\n",
            "Tree depth: 2, Samples: 10\n",
            "Tree depth: 1, Samples: 60\n",
            "Tree depth: 2, Samples: 41\n",
            "Tree depth: 2, Samples: 19\n",
            "Training tree 7/10\n",
            "Tree depth: 0, Samples: 200\n",
            "Tree depth: 1, Samples: 115\n",
            "Tree depth: 2, Samples: 110\n",
            "Tree depth: 3, Samples: 11\n",
            "Tree depth: 3, Samples: 99\n",
            "Tree depth: 2, Samples: 5\n",
            "Tree depth: 1, Samples: 85\n",
            "Tree depth: 2, Samples: 60\n",
            "Tree depth: 3, Samples: 55\n",
            "Tree depth: 3, Samples: 5\n",
            "Tree depth: 2, Samples: 25\n",
            "Training tree 8/10\n",
            "Tree depth: 0, Samples: 200\n",
            "Tree depth: 1, Samples: 111\n",
            "Tree depth: 2, Samples: 33\n",
            "Tree depth: 3, Samples: 28\n",
            "Tree depth: 3, Samples: 5\n",
            "Tree depth: 2, Samples: 78\n",
            "Tree depth: 3, Samples: 65\n",
            "Tree depth: 3, Samples: 13\n",
            "Tree depth: 1, Samples: 89\n",
            "Tree depth: 2, Samples: 5\n",
            "Tree depth: 2, Samples: 84\n",
            "Training tree 9/10\n",
            "Tree depth: 0, Samples: 200\n",
            "Tree depth: 1, Samples: 118\n",
            "Tree depth: 2, Samples: 110\n",
            "Tree depth: 3, Samples: 105\n",
            "Tree depth: 3, Samples: 5\n",
            "Tree depth: 2, Samples: 8\n",
            "Tree depth: 1, Samples: 82\n",
            "Tree depth: 2, Samples: 60\n",
            "Tree depth: 3, Samples: 54\n",
            "Tree depth: 3, Samples: 6\n",
            "Tree depth: 2, Samples: 22\n",
            "Training tree 10/10\n",
            "Tree depth: 0, Samples: 200\n",
            "Tree depth: 1, Samples: 86\n",
            "Tree depth: 2, Samples: 12\n",
            "Tree depth: 2, Samples: 74\n",
            "Tree depth: 3, Samples: 67\n",
            "Tree depth: 3, Samples: 7\n",
            "Tree depth: 1, Samples: 114\n",
            "Tree depth: 2, Samples: 107\n",
            "Tree depth: 3, Samples: 102\n",
            "Tree depth: 3, Samples: 5\n",
            "Tree depth: 2, Samples: 7\n",
            "Training Accuracy: 98.0 %\n",
            "Test Accuracy: 71.31410256410257 %\n"
          ]
        }
      ],
      "source": [
        "X_shuffled, y_shuffled = manual_shuffle(X_train, y_train, random_state=42)\n",
        "X_small = X_shuffled[:200]\n",
        "y_small = y_shuffled[:200]\n",
        "\n",
        "# Create and train Random Forest\n",
        "rf = RandomForest(n_trees=10, max_depth=3, min_samples_split=30)\n",
        "rf.fit(X_small, y_small)\n",
        "\n",
        "# Test predictions\n",
        "train_preds = rf.predict(X_small)\n",
        "train_accuracy = np.sum(train_preds == y_small) / len(y_small)\n",
        "print(\"Training Accuracy:\", train_accuracy * 100, \"%\")\n",
        "\n",
        "test_preds = rf.predict(X_test)\n",
        "test_accuracy = np.sum(test_preds == y_test) / len(y_test)\n",
        "print(\"Test Accuracy:\", test_accuracy * 100, \"%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(self, X_train, y_train):\n",
        "    self.trees = []\n",
        "    for i in range(self.n_trees):\n",
        "        print(f\"Training tree {i+1}/{self.n_trees}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4UVWVlWBsWpX"
      },
      "execution_count": 34,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0tIED3xcxwvsUCbNfXGQJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}